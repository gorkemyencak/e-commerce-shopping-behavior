{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120bae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyarrow\n",
    "\n",
    "projectRoot = Path().resolve().parent\n",
    "sys.path.append(str(projectRoot))\n",
    "\n",
    "dataPath = projectRoot / 'data' / 'raw' / 'e_commerce_shopper_behaviour_and_lifestyle.csv'\n",
    "df_raw = pd.read_csv(dataPath)\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190c60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating numerical and categorical features\n",
    "numerical_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=('object')).columns.tolist()\n",
    "\n",
    "# target variable\n",
    "target = 'monthly_spend'\n",
    "\n",
    "# numeric features excluding the target variable\n",
    "numeric_features = [c for c in numerical_cols if c != target]\n",
    "\n",
    "# datetime conversion\n",
    "df['last_purchase_date'] = pd.to_datetime(\n",
    "    df['last_purchase_date'], \n",
    "    format = '%Y-%m-%d'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ddec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'urban_rural', 'employment_status', 'education_level', 'relationship_status', 'ethnicity', 'language_preference', 'device_type', 'preferred_payment_method', 'shopping_time_of_day', 'budgeting_style']\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding -> only applied to categorical columns with low cardinality\n",
    "low_cardinality_cat_columns = [\n",
    "    c for c in categorical_cols\n",
    "    if df[c].nunique() <= 6\n",
    "]\n",
    "print(low_cardinality_cat_columns)\n",
    "\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    drop_first = True,\n",
    "    columns = low_cardinality_cat_columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a0193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wellbeing Columns: ['environmental_consciousness', 'health_conscious_shopping', 'stress_from_financial_decisions', 'overall_stress_level', 'sleep_quality', 'physical_activity_level', 'mental_health_score']\n",
      "Shopping Engagement Columns: ['browse_to_buy_ratio', 'daily_session_time_minutes', 'shopping_time_of_day_Evening', 'shopping_time_of_day_Morning', 'shopping_time_of_day_Night']\n",
      "Price Awareness Columns: ['coupon_usage_frequency', 'ad_views_per_day', 'ad_clicks_per_day', 'notification_response_rate']\n",
      "Impulse Purchase Columns: ['impulse_purchases_per_month', 'impulse_buying_score']\n",
      "Review Influence Columns: ['review_writing_frequency', 'social_media_influence_score', 'reading_habits', 'social_sharing_frequency']\n",
      "Shopping Funnel Columns: ['cart_abandonment_rate', 'average_order_value', 'wishlist_items_count', 'cart_items_average', 'checkout_abandonments_per_month', 'purchase_conversion_rate']\n"
     ]
    }
   ],
   "source": [
    "### Composite Score columns\n",
    "composite_list = []\n",
    "composite_columns = {}\n",
    "# customer wellbeing columns\n",
    "wellbeing_cols = [\n",
    "    c for c in df.columns\n",
    "    if 'stress' in c.lower() or 'mental' in c.lower() or 'emotional' in c.lower() or 'health' in c.lower() or 'physical' in c.lower() or 'sleep' in c.lower()\n",
    "]\n",
    "print(f'Wellbeing Columns: {wellbeing_cols}')\n",
    "df['wellbeing_score'] = df[wellbeing_cols].mean(axis=1)\n",
    "composite_list.append('wellbeing_score')\n",
    "composite_columns['wellbeing_score'] = wellbeing_cols\n",
    "\n",
    "# shopping engagement columns\n",
    "shopping_engagement_cols = [\n",
    "    c for c in df.columns\n",
    "    if 'time' in c.lower() or 'brows' in c.lower()\n",
    "]\n",
    "print(f'Shopping Engagement Columns: {shopping_engagement_cols}')\n",
    "df['shopping_engagement_score'] = df[shopping_engagement_cols].mean(axis=1)\n",
    "composite_list.append('shopping_engagement_score')\n",
    "composite_columns['shopping_engagement_score'] = shopping_engagement_cols\n",
    "\n",
    "# price awareness columns\n",
    "price_awareness_cols = [\n",
    "    c for c in df.columns\n",
    "    if 'coupon' in c.lower() or 'notification' in c.lower() or 'discount' in c.lower() or 'ad_' in c.lower()\n",
    "]\n",
    "print(f'Price Awareness Columns: {price_awareness_cols}')\n",
    "df['price_awareness_score'] = df[price_awareness_cols].mean(axis=1)\n",
    "composite_list.append('price_awareness_score')\n",
    "composite_columns['price_awareness_score'] = price_awareness_cols\n",
    "\n",
    "# impulse purchase -> Impulse vs Planned shopping behavior\n",
    "impulse_purchase_cols = [\n",
    "    c for c in df.columns\n",
    "    if 'impulse' in c.lower()\n",
    "]\n",
    "print(f'Impulse Purchase Columns: {impulse_purchase_cols}')\n",
    "df['impulse_purchase_score'] = df[impulse_purchase_cols].mean(axis=1)\n",
    "df['planned_purchase_score'] = 10 - df['impulse_purchase_score']\n",
    "composite_list.append('impulse_purchase_score')\n",
    "composite_columns['impulse_purchase_score'] = impulse_purchase_cols\n",
    "\n",
    "# review influence\n",
    "review_influence_cols = [\n",
    "    c for c in df.columns\n",
    "    if 'review' in c.lower() or 'social' in c.lower() or 'reading' in c.lower()\n",
    "]\n",
    "print(f'Review Influence Columns: {review_influence_cols}')\n",
    "df['review_influence_score'] = df[review_influence_cols].mean(axis=1)\n",
    "composite_list.append('review_influence_score')\n",
    "composite_columns['review_influence_score'] = review_influence_cols\n",
    "\n",
    "# shopping funnel behavior\n",
    "shopping_funnel_cols = [\n",
    "    c for c in df.columns\n",
    "    if 'cart' in c.lower() or 'order' in c.lower() or 'wishlist' in c.lower() or 'checkout' in c.lower() or 'purchase_conversion' in c.lower()\n",
    "]\n",
    "print(f'Shopping Funnel Columns: {shopping_funnel_cols}')\n",
    "df['shopping_funnel_score'] = df[shopping_funnel_cols].mean(axis=1)\n",
    "composite_list.append('shopping_funnel_score')\n",
    "composite_columns['shopping_funnel_score'] = shopping_funnel_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990bfd3",
   "metadata": {},
   "source": [
    "#### Validating Composite Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe22cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Validating composite scores - Distribution Check\n",
    "n = len(composite_list)\n",
    "cols = 3 \n",
    "rows = int(np.ceil(n/2))\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    rows,\n",
    "    cols,\n",
    "    figsize = (\n",
    "        cols * 5,\n",
    "        rows * 4\n",
    "    )\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, composite_list):\n",
    "    sns.histplot(\n",
    "        df[col],\n",
    "        ax = ax,\n",
    "        color = 'lightsteelblue',\n",
    "        stat = 'density'\n",
    "    )\n",
    "\n",
    "    sns.kdeplot(\n",
    "        df[col],\n",
    "        ax = ax,\n",
    "        color = 'crimson',\n",
    "        linewidth = 2,\n",
    "        linestyle = '-.'\n",
    "    )\n",
    "\n",
    "    ax.set_title(col.upper().replace('_', ' ').title(), fontweight = 'bold')\n",
    "\n",
    "# remove empty plots in case the composite score list is odd number\n",
    "for ax in axes[n:]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validating composite scores - Correlation among Components\n",
    "n = len(composite_list)\n",
    "cols = 3 \n",
    "rows = int(np.ceil(n/2))\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    rows,\n",
    "    cols,\n",
    "    figsize = (\n",
    "        cols * 5,\n",
    "        rows * 4\n",
    "    )\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "# converting bool values in the composite score dictionary into integers\n",
    "df_imputed = df.copy()\n",
    "\n",
    "for k in composite_columns.keys():\n",
    "    for col in composite_columns[k]:\n",
    "        if col in df_imputed.columns and df_imputed[col].dtype == bool:\n",
    "            df_imputed[col] = df_imputed[col].astype(int)\n",
    "        elif col in df_imputed.columns and df_imputed[col].dtype == str:\n",
    "            df_imputed[col] = df_imputed[col].map({'False':0, 'True': 1})\n",
    "\n",
    "# visualizing correlation heatmaps\n",
    "for ax, col in zip(axes, composite_list):\n",
    "    sns.heatmap(\n",
    "        df_imputed[composite_columns[col]].corr(),\n",
    "        ax = ax,\n",
    "        #color = 'lightsteelblue',\n",
    "        cmap = 'vlag',\n",
    "        cbar = False,\n",
    "        fmt = '.2f',\n",
    "        annot = True,\n",
    "        annot_kws = {\n",
    "            'size': 7,\n",
    "            'weight': 'bold'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ax.set_title(col.upper().replace('_', ' ').title(), fontweight = 'bold')\n",
    "\n",
    "# remove empty plots in case the composite score list is odd number\n",
    "for ax in axes[n:]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d017b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validating composite scores - Predictive Contribution\n",
    "\"\"\"To check the feature importance by Decision Tree whether the composite is more informative than raw features\"\"\"\n",
    "\n",
    "def evaluate_composite_with_decision_tree(\n",
    "        df,\n",
    "        target,\n",
    "        composite_name,\n",
    "        raw_cols,\n",
    "        max_depth = 3,\n",
    "        min_samples_leaf = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare DecisionTreeRegressor performance and importances between raw components and composite features\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Raw features\n",
    "    X_raw = df[raw_cols]\n",
    "    y = df[target]\n",
    "\n",
    "    tree_raw = DecisionTreeRegressor(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=7\n",
    "    )\n",
    "    tree_raw.fit(X_raw, y)\n",
    "\n",
    "    results['raw'] = {\n",
    "        'features': raw_cols,\n",
    "        'importances': tree_raw.feature_importances_,\n",
    "        'r2': tree_raw.score(X_raw, y)\n",
    "    }\n",
    "\n",
    "    # Composite features\n",
    "    X_comp = df[[composite_name]]\n",
    "    y = df[target]\n",
    "\n",
    "    tree_composite = DecisionTreeRegressor(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=7\n",
    "    )\n",
    "    tree_composite.fit(X_comp, y)\n",
    "\n",
    "    results['composite'] = {\n",
    "        'features': composite_name,\n",
    "        'importances': tree_composite.feature_importances_,\n",
    "        'r2': tree_composite.score(X_comp, y)\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# iterating over all composite scores\n",
    "tree_results = {}\n",
    "\n",
    "for composite, raw_cols in composite_columns.items():\n",
    "    \n",
    "    tree_results[composite] = evaluate_composite_with_decision_tree(\n",
    "        df = df_imputed,\n",
    "        target=target,\n",
    "        composite_name=composite,\n",
    "        raw_cols=raw_cols,\n",
    "        max_depth=5,\n",
    "        min_samples_leaf=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d8a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreting feature importances\n",
    "for composite, result in tree_results.items():\n",
    "    \n",
    "    raw_importances = pd.Series(\n",
    "        result['raw']['importances'],\n",
    "        index = result['raw']['features']\n",
    "    ).sort_values(ascending=False)\n",
    "    \n",
    "    print(f'--- {composite.upper()}---')\n",
    "    print()\n",
    "    print('Raw feature importances:')\n",
    "    print(raw_importances)\n",
    "    print()\n",
    "    print(f\"Raw R²: {result['raw']['r2']:.6f}\")\n",
    "    print(f\"Composite R²: {result['composite']['r2']:.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking of composite scores based on decision tree regressor\n",
    "summary = []\n",
    "for composite, result in tree_results.items():\n",
    "    summary.append({\n",
    "        'composite': composite,\n",
    "        'raw_r2': result['raw']['r2'],\n",
    "        'composite_r2': result['composite']['r2']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    summary\n",
    ").sort_values(by='composite_r2', ascending=False)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc55dc",
   "metadata": {},
   "source": [
    "Neither raw features nor composites explain the variance in target variable 'monthly_spend' by themselves. This implies that the target variable is highly noisy, and cannot be predicted from any single behavioral pattern. These findings motivate the use of interaction features, segmentation approaches, and ensemble models in subsequent modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### scaling the final feature table before saving \n",
    "# dropping categorical columns if any exists in the dataframe\n",
    "df_imputed_num = df_imputed.copy()\n",
    "cols_to_drop = [c for c in categorical_cols if c in df_imputed_num.columns]\n",
    "df_imputed_num = df_imputed_num.drop(columns = cols_to_drop)\n",
    "\n",
    "# converting datetime/period columns\n",
    "for col in df_imputed_num.columns:\n",
    "    dtype = df_imputed_num[col].dtype\n",
    "\n",
    "    if isinstance(dtype, pd.PeriodDtype):\n",
    "        df_imputed_num[col] = df_imputed_num[col].astype(str)\n",
    "\n",
    "    elif pd.api.types.is_datetime64_any_dtype(df_imputed_num[col]):\n",
    "        df_imputed_num[col] = df_imputed_num[col].astype('datetime64[ns]')\n",
    "\n",
    "# scaling the final data\n",
    "scl = StandardScaler()\n",
    "\n",
    "scaler_cols = [\n",
    "    c for c in df_imputed_num.columns\n",
    "    if c not in [target] and df_imputed_num[c].dtype != 'uint8'\n",
    "]\n",
    "\n",
    "df_imputed_num[scaler_cols] = scl.fit_transform(df_imputed_num[scaler_cols])\n",
    "df_imputed_num.shape\n",
    "\n",
    "# saving to destination folder\n",
    "outputPath = projectRoot / 'data' / 'processed' \n",
    "outputPath.parent.mkdir(parents=True,exist_ok=True)\n",
    "parquetPath = outputPath / 'features_with_composites.parquet'\n",
    "\n",
    "df_imputed_num.to_parquet(\n",
    "    parquetPath, \n",
    "    engine = 'pyarrow',\n",
    "    compression = 'snappy',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
